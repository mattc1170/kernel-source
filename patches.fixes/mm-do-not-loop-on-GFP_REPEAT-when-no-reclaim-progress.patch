From: Michal Hocko <mhocko@suse.cz>
Subject: mm: do not loop on GFP_REPEAT high order requests if there is no reclaim progress
Patch-mainline: never, fixed differently
References: bnc#1013000

Our customer has reported that
$ echo 40000 > /proc/sys/vm/nr_hugepages
stalls and seemingly lockups on a machine with an uneven NUMA topology

linux:~ # numactl -H
Available: 4 nodes (0-1,6-7)
node 0 cpus:
node 0 size: 2758 MB
node 0 free: 97 MB
node 1 cpus: 0 1 2 3 4 5 6 7
node 1 size: 22767 MB
node 1 free: 1029 MB
node 6 cpus: 8 9 10 11 12 13 14 15
node 6 size: 21999 MB
node 6 free: 378 MB
node 7 cpus:
node 7 size: 3566 MB
node 7 free: 57 MB

Node0 is rather small and without any CPUs which can lead to a lack of
reclaimable memory. This would mean that even zone_reclaimable() which
otherwise overrides no reclaim progress can return false and we might
end up looping inside the allocator without any way out because the number
of reclaimed pages was too small.

The upstream has fixed this by reworking the high order retries implementation
7854ea6c28c6 ("mm: consider compaction feedback also for costly allocation")
but this patch depends on other, quite disruptive changes. This patch is just a
band aid and it makes sure we never retry on costly orders if did_some_progress
reports 0.

Signed-off-by: Michal Hocko <mhocko@suse.cz>

---
 mm/page_alloc.c |    4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -3477,8 +3477,8 @@ retry:
 
 	/* Keep reclaiming pages as long as there is reasonable progress */
 	pages_reclaimed += did_some_progress;
-	if ((did_some_progress && order <= PAGE_ALLOC_COSTLY_ORDER) ||
-	    ((gfp_mask & __GFP_REPEAT) && pages_reclaimed < (1 << order))) {
+	if (did_some_progress && (order <= PAGE_ALLOC_COSTLY_ORDER ||
+	    ((gfp_mask & __GFP_REPEAT) && pages_reclaimed < (1 << order)))) {
 		/* Wait for some write requests to complete then retry */
 		wait_iff_congested(ac->preferred_zoneref->zone, BLK_RW_ASYNC, HZ/50);
 		goto retry;

From 1b16544498a9102204a384ec064a73e5aacb3930 Mon Sep 17 00:00:00 2001
From: Hong Liu <hong.liu@intel.com>
Date: Mon, 11 Jul 2016 13:09:48 +0800
Subject: [PATCH 137/143] drm/i915: wait on a scheduler queue

Introduce a new wait queue to avoid requesters competing with kworker.

Waiters in file_queue_wait() will be waken up as soon as the request is
finished, thus it will compete with the kworker thread (cleaning up the
requests on scheduler), causing CPU time increaing in multi-process case.

In a GPU hang case, scheduler will be waken up at the end to clean up
the queued requests, thus waiters on scheduler queue will be waken up
at last.

Change-Id: I6d79152e4e782d111ce2d9cfba93000ff9b6cbae
Signed-off-by: Hong Liu <hong.liu@intel.com>
---
 drivers/gpu/drm/i915/i915_scheduler.c |   69 +++-----------------------------
 drivers/gpu/drm/i915/i915_scheduler.h |    1 +
 2 files changed, 8 insertions(+), 62 deletions(-)

diff --git a/drivers/gpu/drm/i915/i915_scheduler.c b/drivers/gpu/drm/i915/i915_scheduler.c
index 4d81527..6ea6a28 100644
--- a/drivers/gpu/drm/i915/i915_scheduler.c
+++ b/drivers/gpu/drm/i915/i915_scheduler.c
@@ -193,6 +193,7 @@ int i915_scheduler_init(struct drm_device *dev)
 	scheduler->priority_level_preempt = 900;
 	scheduler->min_flying             = 5;
 	scheduler->file_queue_max         = 256;
+	init_waitqueue_head(&scheduler->busy_queue);
 	scheduler->dump_flags             = I915_SF_DUMP_FORCE   |
 					    I915_SF_DUMP_DETAILS |
 					    I915_SF_DUMP_SEQNO   |
@@ -765,6 +766,7 @@ static void i915_scheduler_file_queue_dec(struct drm_file *file)
 	struct drm_i915_file_private *file_priv = file->driver_priv;
 
 	file_priv->scheduler_queue_length--;
+	wake_up(&file_priv->dev_priv->scheduler->busy_queue);
 }
 
 static int i915_generate_dependencies(struct i915_scheduler *scheduler,
@@ -1305,75 +1307,18 @@ bool i915_scheduler_file_queue_wait(struct drm_file *file)
 	struct drm_i915_file_private *file_priv = file->driver_priv;
 	struct drm_i915_private *dev_priv  = file_priv->dev_priv;
 	struct i915_scheduler *scheduler = dev_priv->scheduler;
-	struct drm_i915_gem_request *req;
-	struct i915_scheduler_queue_entry *node;
-	unsigned reset_counter;
-	int i, ret;
-	struct intel_engine_cs *ring;
+	int ret;
 
 	if (file_priv->scheduler_queue_length < scheduler->file_queue_max)
 		return false;
 
-	do {
-		spin_lock_irq(&scheduler->lock);
+	ret = wait_event_interruptible(scheduler->busy_queue,
+		file_priv->scheduler_queue_length < scheduler->file_queue_max);
 
-		/*
-		 * Find the first (i.e. oldest) request for this file. In the
-		 * case where an app is using multiple rings, this search
-		 * might be skewed by ring. However, worst case is an app has
-		 * queued ~60 requests to a high indexed ring and then one
-		 * request to a low indexed ring. In such a case, the driver
-		 * will wait for longer than necessary but operation will
-		 * still be correct and that case is not rare enough to add
-		 * jiffy based inter-ring checks.
-		 */
-		req = NULL;
-		for_each_ring(ring, dev_priv, i) {
-			for_each_scheduler_node(node, ring->id) {
-				if (I915_SQS_IS_COMPLETE(node))
-					continue;
-
-				if (node->params.file != file)
-					continue;
-
-				req = node->params.request;
-				break;
-			}
-
-			if (req)
-				break;
-		}
-
-		if (!req) {
-			spin_unlock_irq(&scheduler->lock);
-			return false;
-		}
-
-		i915_gem_request_reference(req);
-
-		spin_unlock_irq(&scheduler->lock);
-
-		ret = i915_gem_check_wedge(&dev_priv->gpu_error, false);
-		if (ret)
-			goto err_unref;
-
-		reset_counter = atomic_read(&dev_priv->gpu_error.reset_counter);
-
-		ret = __i915_wait_request(req, reset_counter, true, NULL, NULL, false);
-		if (ret)
-			goto err_unref;
-
-		/* Make sure the request's resources actually get cleared up */
-		i915_scheduler_process_work(req->ring);
-
-		i915_gem_request_unreference(req);
-	} while(file_priv->scheduler_queue_length >= scheduler->file_queue_max);
+	if (ret < 0)
+		return true;
 
 	return false;
-
-err_unref:
-	i915_gem_request_unreference(req);
-	return true;
 }
 
 static int i915_scheduler_dump_locked(struct intel_engine_cs *ring,
diff --git a/drivers/gpu/drm/i915/i915_scheduler.h b/drivers/gpu/drm/i915/i915_scheduler.h
index bb70847..9c023ec 100644
--- a/drivers/gpu/drm/i915/i915_scheduler.h
+++ b/drivers/gpu/drm/i915/i915_scheduler.h
@@ -137,6 +137,7 @@ struct i915_scheduler {
 	int32_t priority_level_preempt;
 	uint32_t min_flying;
 	uint32_t file_queue_max;
+	wait_queue_head_t busy_queue;
 	uint32_t dump_flags;
 
 	/* Statistics: */
-- 
1.7.1


From 70e14838ec74f1f34ccfeb1f0002287bb38c4727 Mon Sep 17 00:00:00 2001
From: John Harrison <john.c.harrison@intel.com>
Date: Tue, 9 Aug 2016 15:33:04 +0800
Subject: [PATCH 144/147] [VPG]: drm/i915: add new counts for scheduler nodes tracking

By adding the new counts (flying and queued) for each node queue
and maintain them when changing node state, we don't need to iterate
through the node queue one by one to get the needed counts.

Signed-off-by: John Harrison <john.c.harrison@intel.com>
---
 drivers/gpu/drm/i915/i915_scheduler.c |   58 ++++++++++++++------------------
 drivers/gpu/drm/i915/i915_scheduler.h |    8 ++++
 2 files changed, 33 insertions(+), 33 deletions(-)

diff --git a/drivers/gpu/drm/i915/i915_scheduler.c b/drivers/gpu/drm/i915/i915_scheduler.c
index ac83b5e..d8eb8c4 100644
--- a/drivers/gpu/drm/i915/i915_scheduler.c
+++ b/drivers/gpu/drm/i915/i915_scheduler.c
@@ -210,7 +210,8 @@ int i915_scheduler_init(struct drm_device *dev)
  * hung when execfinal() was called and thus the ring submission needs to be
  * retried later.
  */
-static void i915_scheduler_node_requeue(struct i915_scheduler_queue_entry *node)
+static void i915_scheduler_node_requeue(struct i915_scheduler *scheduler,
+					struct i915_scheduler_queue_entry *node)
 {
 	WARN_ON(!I915_SQS_IS_FLYING(node));
 
@@ -219,6 +220,8 @@ static void i915_scheduler_node_requeue(struct i915_scheduler_queue_entry *node)
 	node->status = I915_SQS_QUEUED;
 	trace_i915_scheduler_unfly(node->params.ring, node);
 	trace_i915_scheduler_node_state_change(node->params.ring, node);
+	scheduler->counts[node->params.ring->id].flying--;
+	scheduler->counts[node->params.ring->id].queued++;
 }
 
 /*
@@ -235,8 +238,11 @@ static void i915_scheduler_node_kill(struct i915_scheduler *scheduler,
 	if (I915_SQS_IS_FLYING(node)) {
 		trace_i915_scheduler_unfly(node->params.ring, node);
 		scheduler->stats[node->params.ring->id].kill_flying++;
-	} else
+		scheduler->counts[node->params.ring->id].flying--;
+	} else {
 		scheduler->stats[node->params.ring->id].kill_queued++;
+		scheduler->counts[node->params.ring->id].queued--;
+	}
 
 	node->status = I915_SQS_DEAD;
 	trace_i915_scheduler_node_state_change(node->params.ring, node);
@@ -264,6 +270,7 @@ static void i915_scheduler_node_fly(struct i915_scheduler_queue_entry *node)
 
 	trace_i915_scheduler_fly(ring, node);
 	trace_i915_scheduler_node_state_change(ring, node);
+	scheduler->counts[ring->id].flying++;
 
 	if (!(scheduler->flags[ring->id] & I915_SF_INTERRUPTS_ENABLED)) {
 		bool success = true;
@@ -274,19 +281,10 @@ static void i915_scheduler_node_fly(struct i915_scheduler_queue_entry *node)
 	}
 }
 
-static uint32_t i915_scheduler_count_flying(struct i915_scheduler *scheduler,
+static inline uint32_t i915_scheduler_count_flying(struct i915_scheduler *scheduler,
 					    struct intel_engine_cs *ring)
 {
-	struct i915_scheduler_queue_entry *node;
-	uint32_t flying = 0;
-
-	assert_scheduler_lock_held(scheduler);
-
-	for_each_scheduler_node(node, ring->id)
-		if (I915_SQS_IS_FLYING(node))
-			flying++;
-
-	return flying;
+	return scheduler->counts[ring->id].flying;
 }
 
 static void i915_scheduler_priority_bump_clear(struct i915_scheduler *scheduler)
@@ -533,6 +531,7 @@ static int i915_scheduler_pop_from_queue_locked(struct intel_engine_cs *ring,
 		best->status = I915_SQS_POPPED;
 
 		trace_i915_scheduler_node_state_change(ring, best);
+		scheduler->counts[ring->id].queued--;
 
 		ret = 0;
 	} else {
@@ -685,7 +684,7 @@ static int i915_scheduler_submit(struct intel_engine_cs *ring)
 			}
 
 			if (requeue) {
-				i915_scheduler_node_requeue(node);
+				i915_scheduler_node_requeue(scheduler, node);
 				/*
 				 * No point spinning if the ring is currently
 				 * unavailable so just give up and come back
@@ -864,19 +863,12 @@ static int i915_scheduler_queue_execbuffer_bypass(struct i915_scheduler_queue_en
 	return 0;
 }
 
-static uint32_t i915_scheduler_count_incomplete(struct i915_scheduler *scheduler)
+static inline uint32_t i915_scheduler_count_incomplete(struct i915_scheduler *scheduler)
 {
-	struct i915_scheduler_queue_entry *test;
 	int r, incomplete = 0;
 
-	for (r = 0; r < I915_NUM_RINGS; r++) {
-		for_each_scheduler_node(test, r) {
-			if (I915_SQS_IS_COMPLETE(test))
-				continue;
-
-			incomplete++;
-		}
-	}
+	for (r = 0; r < I915_NUM_RINGS; r++)
+		incomplete += scheduler->counts[r].queued + scheduler->counts[r].flying;
 
 	return incomplete;
 }
@@ -983,6 +975,7 @@ int i915_scheduler_queue_execbuffer(struct i915_scheduler_queue_entry *qe)
 
 	trace_i915_scheduler_queue(ring, node);
 	trace_i915_scheduler_node_state_change(ring, node);
+	scheduler->counts[ring->id].queued++;
 
 	spin_unlock_irq(&scheduler->lock);
 
@@ -1032,6 +1025,7 @@ bool i915_scheduler_notify_request(struct drm_i915_gem_request *req)
 	}
 
 	trace_i915_scheduler_node_state_change(req->ring, node);
+	scheduler->counts[req->ring->id].flying--;
 
 	spin_unlock_irqrestore(&scheduler->lock, flags);
 
@@ -1168,18 +1162,10 @@ static bool i915_scheduler_remove(struct i915_scheduler *scheduler,
 				  struct list_head *remove)
 {
 	struct i915_scheduler_queue_entry *node, *node_next;
-	int flying = 0, queued = 0;
 	bool do_submit;
 
 	spin_lock_irq(&scheduler->lock);
 
-	for_each_scheduler_node(node, ring->id) {
-		if (I915_SQS_IS_QUEUED(node))
-			queued++;
-		else if (I915_SQS_IS_FLYING(node))
-			flying++;
-	}
-
 	INIT_LIST_HEAD(remove);
 	list_for_each_entry_safe(node, node_next, &scheduler->node_queue[ring->id], link) {
 		if (!I915_SQS_IS_COMPLETE(node))
@@ -1212,7 +1198,8 @@ static bool i915_scheduler_remove(struct i915_scheduler *scheduler,
 	}
 
 	/* Launch more packets now? */
-	do_submit = (queued > 0) && (flying < scheduler->min_flying);
+	do_submit = scheduler->counts[ring->id].queued > 0 &&
+		    scheduler->counts[ring->id].flying < scheduler->min_flying;
 
 	trace_i915_scheduler_remove(ring, do_submit);
 
@@ -1539,6 +1526,11 @@ int i915_scheduler_query_stats(struct intel_engine_cs *ring,
 		stats->counts[node->status]++;
 	}
 
+	if (stats->counts[I915_SQS_QUEUED] != scheduler->counts[ring->id].queued)
+		printk(KERN_ERR "%s:%d> \x1B[31;1mQueued count mis-match: %d vs %d!\x1B[0m\n", __func__, __LINE__, stats->counts[I915_SQS_QUEUED], scheduler->counts[ring->id].queued);
+	if (stats->counts[I915_SQS_FLYING] != scheduler->counts[ring->id].flying)
+		printk(KERN_ERR "%s:%d> \x1B[31;1mFlying count mis-match: %d vs %d!\x1B[0m\n", __func__, __LINE__, stats->counts[I915_SQS_FLYING], scheduler->counts[ring->id].flying);
+
 	spin_unlock_irq(&scheduler->lock);
 
 	return 0;
diff --git a/drivers/gpu/drm/i915/i915_scheduler.h b/drivers/gpu/drm/i915/i915_scheduler.h
index 279e2c7..ca5867d 100644
--- a/drivers/gpu/drm/i915/i915_scheduler.h
+++ b/drivers/gpu/drm/i915/i915_scheduler.h
@@ -125,11 +125,19 @@ struct i915_scheduler_stats {
 	uint32_t fence_got;
 };
 
+struct i915_scheduler_node_states {
+	uint32_t flying;
+	uint32_t queued;
+};
+
 struct i915_scheduler {
 	struct list_head node_queue[I915_NUM_RINGS];
 	uint32_t flags[I915_NUM_RINGS];
 	spinlock_t lock;
 
+	/* Node counts: */
+	struct i915_scheduler_node_states counts[I915_NUM_RINGS];
+
 	/* Tuning parameters: */
 	int32_t priority_level_min;
 	int32_t priority_level_max;
-- 
1.7.1


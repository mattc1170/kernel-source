From 1cb061b6c56badf5436cfafaea052be087af06ed Mon Sep 17 00:00:00 2001
From: Zhipeng Gong <zhipeng.gong@intel.com>
Date: Tue, 31 May 2016 02:00:08 -0400
Subject: [PATCH 125/143] [VPG]: drm/i915: Move i915_gem_get_seqno to right place.

In i915_gem_request_alloc, the intel_logical_ring_alloc_request_extras
will pin the context which can result in the shrinker being called,
and other BBs could be submitted, as a result reserved_seqno
for the request does not match dev_priv->last_seqno.
Move the seqno allocation after intel_logical_ring_alloc_request_extras.
---
 drivers/gpu/drm/i915/i915_gem.c  |   29 ++++++++++++++++++-----------
 drivers/gpu/drm/i915/intel_lrc.c |   11 -----------
 2 files changed, 18 insertions(+), 22 deletions(-)

Index: current/drivers/gpu/drm/i915/i915_gem.c
===================================================================
--- current.orig/drivers/gpu/drm/i915/i915_gem.c
+++ current/drivers/gpu/drm/i915/i915_gem.c
@@ -3221,23 +3221,17 @@ int i915_gem_request_alloc(struct intel_
 	if (req == NULL)
 		return -ENOMEM;
 
-	/*
-	 * Assign an identifier to track this request through the hardware
-	 * but don't make it live yet. It could change in the future if this
-	 * request gets overtaken. However, it still needs to be allocated
-	 * in advance because the point of submission must not fail and seqno
-	 * allocation can fail.
-	 */
-	ret = i915_gem_get_seqno(ring->dev, &req->reserved_seqno);
-	if (ret)
-		goto err;
-
 	req->i915 = dev_priv;
 	req->ring = ring;
 	req->uniq = dev_priv->request_uniq++;
 	req->ctx  = ctx;
 	i915_gem_context_reference(req->ctx);
 
+	/*
+	 * NB: The logical ring case will pin the context which can result in
+	 * the shrinker being called so becareful about putting other steps 
+	 * before this.
+	 */
 	if (i915.enable_execlists)
 		ret = intel_logical_ring_alloc_request_extras(req);
 	else
@@ -3245,6 +3239,19 @@ int i915_gem_request_alloc(struct intel_
 	if (ret) {
 		i915_gem_context_unreference(req->ctx);
 		goto err;
+	}
+
+	/*
+	 * Assign an identifier to track this request through the hardware
+	 * but don't make it live yet. It could change in the future if this
+	 * request gets overtaken. However, it still needs to be allocated
+	 * in advance because the point of submission must not fail and seqno
+	 * allocation can fail.
+	 */
+	ret = i915_gem_get_seqno(ring->dev, &req->reserved_seqno);
+	if (ret) {
+		i915_gem_context_unreference(req->ctx);
+		goto err;
 	}
 
 	init_waitqueue_head(&req->locked_wait_queue);
Index: current/drivers/gpu/drm/i915/intel_lrc.c
===================================================================
--- current.orig/drivers/gpu/drm/i915/intel_lrc.c
+++ current/drivers/gpu/drm/i915/intel_lrc.c
@@ -2643,7 +2643,6 @@ int intel_lr_context_deferred_alloc(stru
 				     struct intel_engine_cs *ring)
 {
 	struct drm_device *dev = ring->dev;
-	struct drm_i915_private *dev_priv = dev->dev_private;
 	struct drm_i915_gem_object *ctx_obj;
 	uint32_t context_size;
 	struct intel_ringbuffer *ringbuf;
@@ -2697,16 +2696,6 @@ int intel_lr_context_deferred_alloc(stru
 			goto error_ringbuf;
 		}
 
-		if (req->reserved_seqno != dev_priv->last_seqno) {
-			ret = i915_gem_get_seqno(ring->dev, &req->reserved_seqno);
-			if (ret) {
-				DRM_ERROR("ring get seqno: %d\n",
-					ret);
-				i915_gem_request_cancel(req);
-				goto error_ringbuf;
-			}
-		}
-
 		ret = ring->init_context(req);
 		if (ret) {
 			DRM_ERROR("ring init context: %d\n",

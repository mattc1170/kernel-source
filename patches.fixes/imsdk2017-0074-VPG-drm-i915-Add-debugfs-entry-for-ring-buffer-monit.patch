From 5adc0b82032b11760fe47da557a252aba07ddd44 Mon Sep 17 00:00:00 2001
From: Zhipeng Gong <zhipeng.gong@intel.com>
Date: Wed, 26 Nov 2014 09:08:03 +0800
Subject: [PATCH 074/143] [VPG]: drm/i915: Add debugfs entry for ring buffer monitoring

It is used for ring load calculation.
---
 drivers/gpu/drm/i915/i915_debugfs.c |   92 +++++++++++++++++++++++++++++++++++
 1 files changed, 92 insertions(+), 0 deletions(-)

diff --git a/drivers/gpu/drm/i915/i915_debugfs.c b/drivers/gpu/drm/i915/i915_debugfs.c
index 7d633c6..179b25d 100644
--- a/drivers/gpu/drm/i915/i915_debugfs.c
+++ b/drivers/gpu/drm/i915/i915_debugfs.c
@@ -3473,6 +3473,97 @@ static int i915_drrs_status(struct seq_file *m, void *unused)
 
 	return 0;
 }
+static int i915_ringstat_info(struct seq_file *m, void *data)
+{
+	struct drm_info_node *node = (struct drm_info_node *) m->private;
+	struct drm_device *dev = node->minor->dev;
+	struct drm_i915_private *dev_priv = dev->dev_private;
+	struct intel_engine_cs *ring;
+	struct intel_ringbuffer *ringbuf;
+	struct drm_i915_gem_request *gem_request;
+	int ret, i;
+	uint32_t seqno;
+
+	struct ring_info {
+		char * name;
+		int id;
+		int size;
+		int head;
+		int tail;
+		int seqno;
+		int jiffies;
+	};
+	struct ring_info ringstats[I915_NUM_RINGS] = {{0},{0},{0},{0}};
+	/* Need to lock to get valid snapshot - keep overheads to min */
+	ret = mutex_lock_interruptible(&dev->struct_mutex);
+	if (ret) {
+		return ret;
+	}
+
+	if (i915.enable_execlists) {
+		for_each_ring(ring, dev_priv, i) {
+			/*get current completed seqno */
+			seqno = ring->get_seqno(ring, true);
+
+			ringstats[i].name = (char *) ring->name;
+			ringstats[i].id = ring->id;
+			ringstats[i].size = -1;
+			ringstats[i].tail = -1;
+			ringstats[i].seqno = -1; /* set to -1 to indicate empty */
+			ringstats[i].jiffies = -1;
+			ringstats[i].head = -1;
+
+			list_for_each_entry(gem_request, &ring->request_list, list) {
+				/* skip the request if completed */
+				if(i915_seqno_passed(seqno, gem_request->seqno))
+					continue;
+
+				ringstats[i].seqno = gem_request->seqno;
+				ringstats[i].head = 0;
+				break;
+			}
+		}
+	} else {
+		for_each_ring(ring, dev_priv, i) {
+			/*get current completed seqno */
+			seqno = ring->get_seqno(ring, true);
+
+			ringbuf = ring->buffer;
+			ringstats[i].name = (char *) ring->name;
+			ringstats[i].id = ring->id;
+			ringstats[i].size = ringbuf->size;
+			ringstats[i].tail = ringbuf->tail;
+			ringstats[i].seqno = -1; /* set to -1 to indicate empty */
+			ringstats[i].jiffies = 0;
+			ringstats[i].head = ringstats[i].tail;
+
+			list_for_each_entry(gem_request, &ring->request_list, list) {
+				/* skip the request if completed */
+				if(i915_seqno_passed(seqno, gem_request->seqno))
+					continue;
+
+				ringstats[i].jiffies = (int) (jiffies - gem_request->emitted_jiffies);
+				ringstats[i].seqno = gem_request->seqno;
+				ringstats[i].head = gem_request->head;
+				break;
+			}
+		}
+	}
+	mutex_unlock(&dev->struct_mutex);
+
+	/* Now Print the data out */
+	for_each_ring(ring, dev_priv, i) {
+		seq_printf(m,"%s:%d:%d:%d:%d:%d:%d\n",
+			ringstats[i].name,
+			ringstats[i].id,
+			ringstats[i].size,
+			ringstats[i].head,
+			ringstats[i].tail,
+			ringstats[i].seqno,
+			ringstats[i].jiffies );
+	}
+	return 0;
+}
 
 static int i915_scheduler_info(struct seq_file *m, void *unused)
 {
@@ -5520,6 +5611,7 @@ static const struct drm_info_list i915_debugfs_list[] = {
 	{"i915_sseu_status", i915_sseu_status, 0},
 	{"i915_drrs_status", i915_drrs_status, 0},
 	{"i915_rps_boost_info", i915_rps_boost_info, 0},
+	{"i915_ringstats", i915_ringstat_info, 0},
 };
 #define I915_DEBUGFS_ENTRIES ARRAY_SIZE(i915_debugfs_list)
 
-- 
1.7.1


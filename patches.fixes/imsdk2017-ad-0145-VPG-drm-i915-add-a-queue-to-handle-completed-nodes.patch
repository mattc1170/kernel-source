---
 drivers/gpu/drm/i915/i915_scheduler.c |  182 ++++++++++++++++++++++------------
 drivers/gpu/drm/i915/i915_scheduler.h |    1 
 2 files changed, 122 insertions(+), 61 deletions(-)

--- a/drivers/gpu/drm/i915/i915_scheduler.c
+++ b/drivers/gpu/drm/i915/i915_scheduler.c
@@ -184,6 +184,7 @@ int i915_scheduler_init(struct drm_devic
 
 	for (r = 0; r < I915_NUM_RINGS; r++)
 		INIT_LIST_HEAD(&scheduler->node_queue[r]);
+	INIT_LIST_HEAD(&scheduler->completed_queue);
 
 	/* Default tuning values: */
 	scheduler->priority_level_min     = -1023;
@@ -244,6 +245,7 @@ static void i915_scheduler_node_kill(str
 	}
 
 	node->status = I915_SQS_DEAD;
+	list_move(&node->link, &scheduler->completed_queue);
 	trace_i915_scheduler_node_state_change(node->params.ring, node);
 }
 
@@ -885,6 +887,8 @@ bool i915_scheduler_notify_request(struc
 	trace_i915_scheduler_node_state_change(req->ring, node);
 	scheduler->counts[req->ring->id].flying--;
 
+	list_move(&node->link, &scheduler->completed_queue);
+
 	spin_unlock_irqrestore(&scheduler->lock, flags);
 
 	return true;
@@ -914,6 +918,25 @@ static int i915_scheduler_remove_depende
 	}
 
 	/*
+	 * Because of the split list, the loop below will no longer remove
+	 * dependencies between completed nodes. Thus you could (briefly)
+	 * end up with a dangling pointer when one completed node is freed
+	 * but still referenced as a dependency by another completed node.
+	 * In practice I don't think there is anywhere that pointer could
+	 * get dereferenced. However, clearing num_deps here should enforce
+	 * that.
+	 *
+	 * Note that the dereference above is safe because all the
+	 * remove_dependent calls are done en masse for the entire current
+	 * set of completed nodes. Then a later step starts freeing them up.
+	 * And a node being processed in this pass cannot have a dangling
+	 * reference to a completed node from a previous pass because at
+	 * that point this node must have been incomplete and would
+	 * therefore have had the dependency stripped.
+	 */
+	remove->num_deps = 0;
+
+	/*
 	 * Remove this node from the dependency lists of any other node which
 	 * might be waiting on it.
 	 */
@@ -1014,19 +1037,17 @@ static bool i915_scheduler_remove(struct
 				  struct intel_engine_cs *ring,
 				  struct list_head *remove)
 {
-	struct i915_scheduler_queue_entry *node, *node_next;
+	struct i915_scheduler_queue_entry *node;
 	bool do_submit;
 
 	spin_lock_irq(&scheduler->lock);
 
 	INIT_LIST_HEAD(remove);
-	list_for_each_entry_safe(node, node_next, &scheduler->node_queue[ring->id], link) {
-		if (!I915_SQS_IS_COMPLETE(node))
-			break;
 
-		list_del(&node->link);
-		list_add(&node->link, remove);
-		scheduler->stats[ring->id].expired++;
+	list_for_each_entry(node, &scheduler->completed_queue, link) {
+		WARN_ON(!I915_SQS_IS_COMPLETE(node));
+
+		scheduler->stats[node->params.ring->id].expired++;
 
 		/* Strip the dependency info while the mutex is still locked */
 		i915_scheduler_remove_dependent(scheduler, node);
@@ -1036,9 +1057,8 @@ static bool i915_scheduler_remove(struct
 			i915_scheduler_file_queue_dec(scheduler);
 			node->params.file = NULL;
 		}
-
-		continue;
 	}
+	list_splice_init(&scheduler->completed_queue, remove);
 
 	/*
 	 * Release the interrupt reference count if there are no longer any
@@ -1069,7 +1089,8 @@ static void i915_scheduler_process_work(
 	bool do_submit;
 	struct list_head remove;
 
-	if (list_empty(&scheduler->node_queue[ring->id]))
+	if (list_empty(&scheduler->node_queue[ring->id]) &&
+	    list_empty(&scheduler->completed_queue))
 		return;
 
 	/* Remove completed nodes. */
@@ -1091,7 +1112,7 @@ static void i915_scheduler_process_work(
 		node = list_first_entry(&remove, typeof(*node), link);
 		list_del(&node->link);
 
-		trace_i915_scheduler_destroy(ring, node);
+		trace_i915_scheduler_destroy(node->params.ring, node);
 
 		/* Free up all the DRM references */
 		i915_scheduler_clean_node(node);
@@ -1160,6 +1181,62 @@ bool i915_scheduler_file_queue_wait(stru
 #undef COND
 }
 
+static void
+i915_scheduler_dump_node_details(struct i915_scheduler *scheduler,
+				 struct intel_engine_cs *ring,
+				 struct i915_scheduler_queue_entry *node,
+				 uint32_t counts[])
+{
+	int i, deps;
+	uint32_t count;
+
+	if (node->status < I915_SQS_MAX) {
+		count = counts[node->status]++;
+	} else {
+		DRM_DEBUG_DRIVER("<%s>   Unknown status: %d!\n",
+				ring->name, node->status);
+		count = -1;
+	}
+
+	deps = 0;
+	for (i = 0; i < node->num_deps; i++)
+		if (i915_scheduler_is_dependency_valid(node, i))
+			deps++;
+
+	DRM_DEBUG_DRIVER("<%s>   %c:%02d> uniq = %d, seqno"
+			 " = %d/%s, deps = %d / %d, %s [pri = "
+			 "%4d]\n", ring->name,
+			 i915_scheduler_queue_status_chr(node->status),
+			 count,
+			 node->params.request->uniq,
+			 node->params.request->seqno,
+			 node->params.ring->name,
+			 deps, node->num_deps,
+			 i915_qe_state_str(node),
+			 node->priority);
+
+	if ((scheduler->flags[ring->id] & I915_SF_DUMP_DEPENDENCIES) == 0)
+		return;
+
+	for (i = 0; i < node->num_deps; i++) {
+		if (!node->dep_list[i])
+			continue;
+
+		DRM_DEBUG_DRIVER("<%s>       |-%c:"
+				 "%02d%c uniq = %d, seqno = %d/%s, %s [pri = %4d]\n",
+				 ring->name,
+				 i915_scheduler_queue_status_chr(node->dep_list[i]->status),
+				 i,
+				 i915_scheduler_is_dependency_valid(node, i)
+				 ? '>' : '#',
+				 node->dep_list[i]->params.request->uniq,
+				 node->dep_list[i]->params.request->seqno,
+				 node->dep_list[i]->params.ring->name,
+				 i915_qe_state_str(node->dep_list[i]),
+				 node->dep_list[i]->priority);
+	}
+}
+
 static int i915_scheduler_dump_locked(struct intel_engine_cs *ring,
 				      const char *msg)
 {
@@ -1179,12 +1256,15 @@ static int i915_scheduler_dump_locked(st
 			queued++;
 		else if (I915_SQS_IS_FLYING(node))
 			flying++;
-		else if (I915_SQS_IS_COMPLETE(node))
-			complete++;
 		else
 			other++;
 	}
 
+	list_for_each_entry(node, &scheduler->completed_queue, link) {
+		if (node->params.ring == ring)
+			complete++;
+	}
+
 	b_dump = (flying != old_flying) ||
 		 (queued != old_queued) ||
 		 (complete != old_complete);
@@ -1228,55 +1308,21 @@ static int i915_scheduler_dump_locked(st
 	}
 
 	if (scheduler->flags[ring->id] & I915_SF_DUMP_DETAILS) {
-		int i, deps;
-		uint32_t count, counts[I915_SQS_MAX];
+		uint32_t counts[I915_SQS_MAX];
 
 		memset(counts, 0x00, sizeof(counts));
 
 		for_each_scheduler_node(node, ring->id) {
-			if (node->status < I915_SQS_MAX) {
-				count = counts[node->status]++;
-			} else {
-				DRM_DEBUG_DRIVER("<%s>   Unknown status: %d!\n",
-						 ring->name, node->status);
-				count = -1;
-			}
-
-			deps = 0;
-			for (i = 0; i < node->num_deps; i++)
-				if (i915_scheduler_is_dependency_valid(node, i))
-					deps++;
-
-			DRM_DEBUG_DRIVER("<%s>   %c:%02d> uniq = %d, seqno"
-					 " = %d/%s, deps = %d / %d, %s [pri = "
-					 "%4d]\n", ring->name,
-					 i915_scheduler_queue_status_chr(node->status),
-					 count,
-					 node->params.request->uniq,
-					 node->params.request->seqno,
-					 node->params.ring->name,
-					 deps, node->num_deps,
-					 i915_qe_state_str(node),
-					 node->priority);
+			i915_scheduler_dump_node_details(scheduler,
+							 ring, node, counts);
+		}
 
-			if ((scheduler->flags[ring->id] & I915_SF_DUMP_DEPENDENCIES)
-				== 0)
+		list_for_each_entry(node, &scheduler->completed_queue, link) {
+			if (node->params.ring != ring)
 				continue;
 
-			for (i = 0; i < node->num_deps; i++)
-				if (node->dep_list[i])
-					DRM_DEBUG_DRIVER("<%s>       |-%c:"
-						"%02d%c uniq = %d, seqno = %d/%s, %s [pri = %4d]\n",
-						ring->name,
-						i915_scheduler_queue_status_chr(node->dep_list[i]->status),
-						i,
-						i915_scheduler_is_dependency_valid(node, i)
-							? '>' : '#',
-						node->dep_list[i]->params.request->uniq,
-						node->dep_list[i]->params.request->seqno,
-						node->dep_list[i]->params.ring->name,
-						i915_qe_state_str(node->dep_list[i]),
-						node->dep_list[i]->priority);
+			i915_scheduler_dump_node_details(scheduler,
+							 ring, node, counts);
 		}
 	}
 
@@ -1377,6 +1423,21 @@ int i915_scheduler_query_stats(struct in
 		stats->counts[node->status]++;
 	}
 
+	list_for_each_entry(node, &scheduler->completed_queue, link) {
+		if (node->params.ring != ring)
+			continue;
+
+		if (node->status >= I915_SQS_MAX) {
+			DRM_DEBUG_DRIVER("Invalid node state: %d! [uniq = %d, seqno = %d]\n",
+					 node->status, node->params.request->uniq,
+					 node->params.request->seqno);
+
+			stats->counts[I915_SQS_MAX]++;
+			continue;
+		}
+		stats->counts[node->status]++;
+	}
+
 	if (stats->counts[I915_SQS_QUEUED] != scheduler->counts[ring->id].queued)
 		printk(KERN_ERR "%s:%d> \x1B[31;1mQueued count mis-match: %d vs %d!\x1B[0m\n", __func__, __LINE__, stats->counts[I915_SQS_QUEUED], scheduler->counts[ring->id].queued);
 	if (stats->counts[I915_SQS_FLYING] != scheduler->counts[ring->id].flying)
@@ -1682,12 +1743,11 @@ void i915_scheduler_closefile(struct drm
 			if (node->params.file != file)
 				continue;
 
-			if (!I915_SQS_IS_COMPLETE(node))
-				DRM_DEBUG_DRIVER("Closing file handle with outstanding work: %d:%d/%s on %s\n",
-						 node->params.request->uniq,
-						 node->params.request->seqno,
-						 i915_qe_state_str(node),
-						 ring->name);
+			DRM_DEBUG_DRIVER("Closing file handle with outstanding work: %d:%d/%s on %s\n",
+					 node->params.request->uniq,
+					 node->params.request->seqno,
+					 i915_qe_state_str(node),
+					 ring->name);
 
 			i915_scheduler_file_queue_dec(scheduler);
 			node->params.file = NULL;
--- a/drivers/gpu/drm/i915/i915_scheduler.h
+++ b/drivers/gpu/drm/i915/i915_scheduler.h
@@ -119,6 +119,7 @@ struct i915_scheduler_node_states {
 
 struct i915_scheduler {
 	struct list_head node_queue[I915_NUM_RINGS];
+	struct list_head completed_queue;
 	uint32_t flags[I915_NUM_RINGS];
 	spinlock_t lock;
 

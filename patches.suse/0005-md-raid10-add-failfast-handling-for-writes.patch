From 3c5308285cad0d6617e9535492c424beb47383f1 Mon Sep 17 00:00:00 2001
From: NeilBrown <neilb@suse.de>
Date: Thu, 24 Nov 2011 14:19:30 +1100
Subject: [PATCH 5/5] md/raid10 - add failfast handling for writes.
References: Fate#311379
Git-commit: 1919cbb23bf1b3e0fdb7b6edfb7369f920744087
Patch-mainline: v4.10

When writing to a fastfail device we use REQ_FASTFAIL_DEV unless it is
the only device being written to.
For resync/recovery assume there was a working device to read from so
always use REQ_FASTFAIL_DEV.

If a write for resync/recovery fails we just fail the device - there
is not much else to do.

If a normal write fail but the device cannot be failed (must be only
one left) we queue for write error handling.

Signed-off-by: NeilBrown <neilb@suse.de>
---
 drivers/md/raid10.c |   28 +++++++++++++++++++++++++++-
 1 file changed, 27 insertions(+), 1 deletion(-)

--- a/drivers/md/raid10.c
+++ b/drivers/md/raid10.c
@@ -447,6 +447,7 @@ static void raid10_end_write_request(str
 	struct r10conf *conf = r10_bio->mddev->private;
 	int slot, repl;
 	struct md_rdev *rdev = NULL;
+	struct bio *to_put = NULL;
 
 	dev = find_bio_disk(conf, r10_bio, bio, &slot, &repl);
 
@@ -471,8 +472,23 @@ static void raid10_end_write_request(str
 			if (!test_and_set_bit(WantReplacement, &rdev->flags))
 				set_bit(MD_RECOVERY_NEEDED,
 					&rdev->mddev->recovery);
-			set_bit(R10BIO_WriteError, &r10_bio->state);
+
 			dec_rdev = 0;
+			if (test_bit(FailFast, &rdev->flags)) {
+				md_error(rdev->mddev, rdev);
+				if (!test_bit(Faulty, &rdev->flags))
+					/* This is the only remaining device,
+					 * We need to retry the write without
+					 * FailFast
+					 */
+					set_bit(R10BIO_WriteError, &r10_bio->state);
+				else {
+					r10_bio->devs[slot].bio = NULL;
+					to_put = bio;
+					dec_rdev = 1;
+				}
+			} else
+				set_bit(R10BIO_WriteError, &r10_bio->state);
 		}
 	} else {
 		/*
@@ -522,6 +538,8 @@ static void raid10_end_write_request(str
 	one_write_done(r10_bio);
 	if (dec_rdev)
 		rdev_dec_pending(rdev, conf->mddev);
+	if (to_put)
+		bio_put(to_put);
 }
 
 /*
@@ -1056,6 +1074,7 @@ static void raid10_unplug(struct blk_plu
 	kfree(plug);
 }
 
+static int enough(struct r10conf *conf, int ignore);
 static void __make_request(struct mddev *mddev, struct bio *bio)
 {
 	struct r10conf *conf = mddev->private;
@@ -1415,6 +1434,9 @@ retry_write:
 			mbio->bi_end_io	= raid10_end_write_request;
 			mbio->bi_rw =
 				WRITE | do_sync | do_fua | do_discard | do_same;
+			if (test_bit(FailFast, &conf->mirrors[d].rdev->flags) &&
+			    enough(conf, d))
+				mbio->bi_rw |= REQ_FAILFAST_DEV;
 			mbio->bi_private = r10_bio;
 
 			atomic_inc(&r10_bio->remaining);
@@ -2017,6 +2039,8 @@ static void sync_request_write(struct md
 		atomic_inc(&r10_bio->remaining);
 		md_sync_acct(conf->mirrors[d].rdev->bdev, bio_sectors(tbio));
 
+		if (test_bit(FailFast, &conf->mirrors[d].rdev->flags))
+			tbio->bi_rw |= REQ_FAILFAST_DEV;
 		tbio->bi_iter.bi_sector += conf->mirrors[d].rdev->data_offset;
 		tbio->bi_bdev = conf->mirrors[d].rdev->bdev;
 		generic_make_request(tbio);
@@ -3273,6 +3297,8 @@ static sector_t sync_request(struct mdde
 			bio->bi_rw = WRITE;
 			bio->bi_iter.bi_sector = sector +
 				conf->mirrors[d].replacement->data_offset;
+			if (test_bit(FailFast, &conf->mirrors[d].rdev->flags))
+				bio->bi_rw |= REQ_FAILFAST_DEV;
 			bio->bi_bdev = conf->mirrors[d].replacement->bdev;
 			count++;
 		}

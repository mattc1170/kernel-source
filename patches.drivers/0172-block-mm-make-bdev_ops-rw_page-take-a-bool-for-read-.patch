From: Jens Axboe <axboe@fb.com>
Date: Fri, 5 Aug 2016 08:11:04 -0600
Subject: block/mm: make bdev_ops->rw_page() take a bool for read/write
References: bnc#1023798,FATE#321463
Patch-Mainline: v4.8-rc1
Git-commit: c11f0c0b5bb949673e4fc16c742f0316ae4ced20

Commit abf545484d31 changed it from an 'rw' flags type to the
newer ops based interface, but now we're effectively leaking
some bdev internals to the rest of the kernel. Since we only
care about whether it's a read or a write at that level, just
pass in a bool 'is_write' parameter instead.

Then we can also move op_is_write() and friends back under
CONFIG_BLOCK protection.

Reviewed-by: Mike Christie <mchristi@redhat.com>
Signed-off-by: Jens Axboe <axboe@fb.com>
Acked-by: Hannes Reinecke <hare@suse.de>
---
 drivers/block/brd.c           |   16 ++++++++--------
 drivers/block/zram/zram_drv.c |   23 ++++++++++++-----------
 drivers/nvdimm/btt.c          |   12 ++++++------
 drivers/nvdimm/pmem.c         |   14 +++++++-------
 fs/block_dev.c                |    6 ++----
 fs/mpage.c                    |    2 +-
 include/linux/blk_types.h     |   22 +++++++++++-----------
 include/linux/blkdev.h        |    2 +-
 include/linux/fs.h            |    3 +--
 include/linux/pagemap.h       |    2 +-
 mm/filemap.c                  |    4 ++--
 11 files changed, 52 insertions(+), 54 deletions(-)

--- a/drivers/block/brd.c
+++ b/drivers/block/brd.c
@@ -300,20 +300,20 @@ static void copy_from_brd(void *dst, str
  * Process a single bvec of a bio.
  */
 static int brd_do_bvec(struct brd_device *brd, struct page *page,
-			unsigned int len, unsigned int off, int op,
+			unsigned int len, unsigned int off, bool is_write,
 			sector_t sector)
 {
 	void *mem;
 	int err = 0;
 
-	if (op_is_write(op)) {
+	if (is_write) {
 		err = copy_to_brd_setup(brd, sector, len);
 		if (err)
 			goto out;
 	}
 
 	mem = kmap_atomic(page);
-	if (!op_is_write(op)) {
+	if (!is_write) {
 		copy_from_brd(mem + off, brd, sector, len);
 		flush_dcache_page(page);
 	} else {
@@ -350,8 +350,8 @@ static blk_qc_t brd_make_request(struct
 		unsigned int len = bvec.bv_len;
 		int err;
 
-		err = brd_do_bvec(brd, bvec.bv_page, len,
-					bvec.bv_offset, bio_op(bio), sector);
+		err = brd_do_bvec(brd, bvec.bv_page, len, bvec.bv_offset,
+					op_is_write(bio_op(bio)), sector);
 		if (err)
 			goto io_error;
 		sector += len >> SECTOR_SHIFT;
@@ -366,11 +366,11 @@ io_error:
 }
 
 static int brd_rw_page(struct block_device *bdev, sector_t sector,
-		       struct page *page, int op)
+		       struct page *page, bool is_write)
 {
 	struct brd_device *brd = bdev->bd_disk->private_data;
-	int err = brd_do_bvec(brd, page, PAGE_CACHE_SIZE, 0, op, sector);
-	page_endio(page, op, err);
+	int err = brd_do_bvec(brd, page, PAGE_CACHE_SIZE, 0, is_write, sector);
+	page_endio(page, is_write, err);
 	return err;
 }
 
--- a/drivers/block/zram/zram_drv.c
+++ b/drivers/block/zram/zram_drv.c
@@ -810,15 +810,16 @@ static void zram_bio_discard(struct zram
 }
 
 static int zram_bvec_rw(struct zram *zram, struct bio_vec *bvec, u32 index,
-			int offset, int op)
+			int offset, bool is_write)
 {
 	unsigned long start_time = jiffies;
+	int rw_acct = is_write ? REQ_OP_WRITE : REQ_OP_READ;
 	int ret;
 
-	generic_start_io_acct(op, bvec->bv_len >> SECTOR_SHIFT,
+	generic_start_io_acct(rw_acct, bvec->bv_len >> SECTOR_SHIFT,
 			&zram->disk->part0);
 
-	if (!op_is_write(op)) {
+	if (!is_write) {
 		atomic64_inc(&zram->stats.num_reads);
 		ret = zram_bvec_read(zram, bvec, index, offset);
 	} else {
@@ -826,10 +827,10 @@ static int zram_bvec_rw(struct zram *zra
 		ret = zram_bvec_write(zram, bvec, index, offset);
 	}
 
-	generic_end_io_acct(op, &zram->disk->part0, start_time);
+	generic_end_io_acct(rw_acct, &zram->disk->part0, start_time);
 
 	if (unlikely(ret)) {
-		if (!op_is_write(op))
+		if (!is_write)
 			atomic64_inc(&zram->stats.failed_reads);
 		else
 			atomic64_inc(&zram->stats.failed_writes);
@@ -870,17 +871,17 @@ static void __zram_make_request(struct z
 			bv.bv_offset = bvec.bv_offset;
 
 			if (zram_bvec_rw(zram, &bv, index, offset,
-					 bio_op(bio)) < 0)
+					 op_is_write(bio_op(bio))) < 0)
 				goto out;
 
 			bv.bv_len = bvec.bv_len - max_transfer_size;
 			bv.bv_offset += max_transfer_size;
 			if (zram_bvec_rw(zram, &bv, index + 1, 0,
-					 bio_op(bio)) < 0)
+					 op_is_write(bio_op(bio))) < 0)
 				goto out;
 		} else
 			if (zram_bvec_rw(zram, &bvec, index, offset,
-					 bio_op(bio)) < 0)
+					 op_is_write(bio_op(bio))) < 0)
 				goto out;
 
 		update_position(&index, &offset, &bvec);
@@ -937,7 +938,7 @@ static void zram_slot_free_notify(struct
 }
 
 static int zram_rw_page(struct block_device *bdev, sector_t sector,
-		       struct page *page, int op)
+		       struct page *page, bool is_write)
 {
 	int offset, err = -EIO;
 	u32 index;
@@ -961,7 +962,7 @@ static int zram_rw_page(struct block_dev
 	bv.bv_len = PAGE_SIZE;
 	bv.bv_offset = 0;
 
-	err = zram_bvec_rw(zram, &bv, index, offset, op);
+	err = zram_bvec_rw(zram, &bv, index, offset, is_write);
 put_zram:
 	zram_meta_put(zram);
 out:
@@ -974,7 +975,7 @@ out:
 	 * (e.g., SetPageError, set_page_dirty and extra works).
 	 */
 	if (err == 0)
-		page_endio(page, op, 0);
+		page_endio(page, is_write, 0);
 	return err;
 }
 
--- a/drivers/nvdimm/btt.c
+++ b/drivers/nvdimm/btt.c
@@ -1133,11 +1133,11 @@ static int btt_write_pg(struct btt *btt,
 
 static int btt_do_bvec(struct btt *btt, struct bio_integrity_payload *bip,
 			struct page *page, unsigned int len, unsigned int off,
-			int op, sector_t sector)
+			bool is_write, sector_t sector)
 {
 	int ret;
 
-	if (!op_is_write(op)) {
+	if (!is_write) {
 		ret = btt_read_pg(btt, bip, page, off, sector, len);
 		flush_dcache_page(page);
 	} else {
@@ -1180,7 +1180,7 @@ static blk_qc_t btt_make_request(struct
 		BUG_ON(len % btt->sector_size);
 
 		err = btt_do_bvec(btt, bip, bvec.bv_page, len, bvec.bv_offset,
-				  bio_op(bio), iter.bi_sector);
+				  op_is_write(bio_op(bio)), iter.bi_sector);
 		if (err) {
 			dev_info(&btt->nd_btt->dev,
 					"io error in %s sector %lld, len %d,\n",
@@ -1200,14 +1200,14 @@ out:
 }
 
 static int btt_rw_page(struct block_device *bdev, sector_t sector,
-		struct page *page, int op)
+		struct page *page, bool is_write)
 {
 	struct btt *btt = bdev->bd_disk->private_data;
 	int rc;
 
-	rc = btt_do_bvec(btt, NULL, page, PAGE_CACHE_SIZE, 0, op, sector);
+	rc = btt_do_bvec(btt, NULL, page, PAGE_CACHE_SIZE, 0, is_write, sector);
 	if (rc == 0)
-		page_endio(page, op, 0);
+		page_endio(page, is_write, 0);
 
 	return rc;
 }
--- a/drivers/nvdimm/pmem.c
+++ b/drivers/nvdimm/pmem.c
@@ -98,7 +98,7 @@ static int read_pmem(struct page *page,
 }
 
 static int pmem_do_bvec(struct pmem_device *pmem, struct page *page,
-			unsigned int len, unsigned int off, int op,
+			unsigned int len, unsigned int off, bool is_write,
 			sector_t sector)
 {
 	int rc = 0;
@@ -109,7 +109,7 @@ static int pmem_do_bvec(struct pmem_devi
 	if (unlikely(is_bad_pmem(&pmem->bb, sector, len)))
 		bad_pmem = true;
 
-	if (!op_is_write(op)) {
+	if (!is_write) {
 		if (unlikely(bad_pmem))
 			rc = -EIO;
 		else {
@@ -163,7 +163,7 @@ static blk_qc_t pmem_make_request(struct
 	do_acct = nd_iostat_start(bio, &start);
 	bio_for_each_segment(bvec, bio, iter) {
 		rc = pmem_do_bvec(pmem, bvec.bv_page, bvec.bv_len,
-				bvec.bv_offset, bio_op(bio),
+				bvec.bv_offset, op_is_write(bio_op(bio)),
 				iter.bi_sector);
 		if (rc) {
 			bio->bi_error = rc;
@@ -181,13 +181,13 @@ static blk_qc_t pmem_make_request(struct
 }
 
 static int pmem_rw_page(struct block_device *bdev, sector_t sector,
-		       struct page *page, int op)
+		       struct page *page, bool is_write)
 {
 	struct pmem_device *pmem = bdev->bd_queue->queuedata;
 	int rc;
 
-	rc = pmem_do_bvec(pmem, page, PAGE_SIZE, 0, op, sector);
-	if(op_is_write(op))
+	rc = pmem_do_bvec(pmem, page, PAGE_SIZE, 0, is_write, sector);
+	if(is_write)
 		wmb_pmem();
 
 	/*
@@ -197,7 +197,7 @@ static int pmem_rw_page(struct block_dev
 	 * caused by double completion.
 	 */
 	if (rc == 0)
-		page_endio(page, op, 0);
+		page_endio(page, is_write, 0);
 
 	return rc;
 }
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -414,8 +414,7 @@ int bdev_read_page(struct block_device *
 	result = blk_queue_enter(bdev->bd_queue, false);
 	if (result)
 		return result;
-	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page,
-			      REQ_OP_READ);
+	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, false);
 	blk_queue_exit(bdev->bd_queue);
 	return result;
 }
@@ -453,8 +452,7 @@ int bdev_write_page(struct block_device
 		return result;
 
 	set_page_writeback(page);
-	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page,
-			      REQ_OP_WRITE);
+	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, true);
 	if (result)
 		end_page_writeback(page);
 	else
--- a/fs/mpage.c
+++ b/fs/mpage.c
@@ -49,7 +49,7 @@ static void mpage_end_io(struct bio *bio
 
 	bio_for_each_segment_all(bv, bio, i) {
 		struct page *page = bv->bv_page;
-		page_endio(page, bio_op(bio), bio->bi_error);
+		page_endio(page, op_is_write(bio_op(bio)), bio->bi_error);
 	}
 
 	bio_put(bio);
--- a/include/linux/blk_types.h
+++ b/include/linux/blk_types.h
@@ -26,17 +26,6 @@ struct bio_vec {
 	unsigned int	bv_offset;
 };
 
-enum req_op {
-	REQ_OP_READ,
-	REQ_OP_WRITE,
-	REQ_OP_DISCARD,		/* request to discard sectors */
-	REQ_OP_SECURE_ERASE,	/* request to securely erase sectors */
-	REQ_OP_WRITE_SAME,	/* write same block many times */
-	REQ_OP_FLUSH,		/* request for cache flush */
-};
-
-#define REQ_OP_BITS 3
-
 #ifdef CONFIG_BLOCK
 
 struct bvec_iter {
@@ -259,6 +248,17 @@ enum rq_flag_bits {
 #define REQ_HASHED		(1ULL << __REQ_HASHED)
 #define REQ_MQ_INFLIGHT		(1ULL << __REQ_MQ_INFLIGHT)
 
+enum req_op {
+	REQ_OP_READ,
+	REQ_OP_WRITE,
+	REQ_OP_DISCARD,		/* request to discard sectors */
+	REQ_OP_SECURE_ERASE,	/* request to securely erase sectors */
+	REQ_OP_WRITE_SAME,	/* write same block many times */
+	REQ_OP_FLUSH,		/* request for cache flush */
+};
+
+#define REQ_OP_BITS 3
+
 typedef unsigned int blk_qc_t;
 #define BLK_QC_T_NONE	-1U
 #define BLK_QC_T_SHIFT	16
--- a/include/linux/blkdev.h
+++ b/include/linux/blkdev.h
@@ -1672,7 +1672,7 @@ struct blk_dax_ctl {
 struct block_device_operations {
 	int (*open) (struct block_device *, fmode_t);
 	void (*release) (struct gendisk *, fmode_t);
-	int (*rw_page)(struct block_device *, sector_t, struct page *, int op);
+	int (*rw_page)(struct block_device *, sector_t, struct page *, bool);
 	int (*ioctl) (struct block_device *, fmode_t, unsigned, unsigned long);
 	int (*compat_ioctl) (struct block_device *, fmode_t, unsigned, unsigned long);
 	long (*direct_access)(struct block_device *, sector_t, void **, pfn_t *,
--- a/include/linux/fs.h
+++ b/include/linux/fs.h
@@ -2435,13 +2435,12 @@ extern void init_special_inode(struct in
 extern void make_bad_inode(struct inode *);
 extern int is_bad_inode(struct inode *);
 
+#ifdef CONFIG_BLOCK
 static inline bool op_is_write(unsigned int op)
 {
 	return op == REQ_OP_READ ? false : true;
 }
 
-#ifdef CONFIG_BLOCK
-
 /*
  * return data direction, READ or WRITE
  */
--- a/include/linux/pagemap.h
+++ b/include/linux/pagemap.h
@@ -548,7 +548,7 @@ static inline void wait_on_page_writebac
 extern void end_page_writeback(struct page *page);
 void wait_for_stable_page(struct page *page);
 
-void page_endio(struct page *page, int op, int err);
+void page_endio(struct page *page, bool is_write, int err);
 
 /*
  * Add an arbitrary waiter to a page's wait queue
--- a/mm/filemap.c
+++ b/mm/filemap.c
@@ -878,9 +878,9 @@ EXPORT_SYMBOL(end_page_writeback);
  * After completing I/O on a page, call this routine to update the page
  * flags appropriately
  */
-void page_endio(struct page *page, int op, int err)
+void page_endio(struct page *page, bool is_write, int err)
 {
-	if (!op_is_write(op)) {
+	if (!is_write) {
 		if (!err) {
 			SetPageUptodate(page);
 		} else {

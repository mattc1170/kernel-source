From bce977310416a2b6c9ad774dfe2071eaacd3d90b Mon Sep 17 00:00:00 2001
From: Sara Sharon <sara.sharon@intel.com>
Date: Mon, 25 Jan 2016 18:14:49 +0200
Subject: [PATCH] iwlwifi: pcie: enable multi-queue rx path
Git-commit: bce977310416a2b6c9ad774dfe2071eaacd3d90b
Patch-mainline: 4.6-rc1
References: FATE#321353, FATE#323335

Previous patches enabled new 9000 hardware DMA for one queue
only.
Enable the actual multi-queue path and configuration now.
This requires also per-queue NAPI struct.

Signed-off-by: Sara Sharon <sara.sharon@intel.com>
Signed-off-by: Emmanuel Grumbach <emmanuel.grumbach@intel.com>
Acked-by: Takashi Iwai <tiwai@suse.de>

---
 drivers/net/wireless/iwlwifi/pcie/internal.h |    2 -
 drivers/net/wireless/iwlwifi/pcie/rx.c       |   35 ++++++++++++++++++++-------
 drivers/net/wireless/iwlwifi/pcie/trans.c    |   14 ----------
 3 files changed, 29 insertions(+), 22 deletions(-)

--- a/drivers/net/wireless/iwlwifi/pcie/internal.h
+++ b/drivers/net/wireless/iwlwifi/pcie/internal.h
@@ -136,6 +136,7 @@ struct iwl_rxq {
 	struct iwl_rb_status *rb_stts;
 	dma_addr_t rb_stts_dma;
 	spinlock_t lock;
+	struct napi_struct napi;
 	struct iwl_rx_mem_buffer *queue[RX_QUEUE_SIZE];
 };
 
@@ -345,7 +346,6 @@ struct iwl_trans_pcie {
 	struct iwl_drv *drv;
 
 	struct net_device napi_dev;
-	struct napi_struct napi;
 
 	struct __percpu iwl_tso_hdr_page *tso_hdr_page;
 
--- a/drivers/net/wireless/iwlwifi/pcie/rx.c
+++ b/drivers/net/wireless/iwlwifi/pcie/rx.c
@@ -2,6 +2,7 @@
  *
  * Copyright(c) 2003 - 2014 Intel Corporation. All rights reserved.
  * Copyright(c) 2013 - 2015 Intel Mobile Communications GmbH
+ * Copyright(c) 2016 Intel Deutschland GmbH
  *
  * Portions of this file are derived from the ipw3945 project, as well
  * as portions of the ieee80211 subsystem header files.
@@ -730,7 +731,7 @@ static void iwl_pcie_rx_hw_init(struct i
 		iwl_set_bit(trans, CSR_INT_COALESCING, IWL_HOST_INT_OPER_MODE);
 }
 
-static void iwl_pcie_rx_mq_hw_init(struct iwl_trans *trans, struct iwl_rxq *rxq)
+static void iwl_pcie_rx_mq_hw_init(struct iwl_trans *trans)
 {
 	struct iwl_trans_pcie *trans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);
 	u32 rb_size, enabled = 0;
@@ -759,13 +760,13 @@ static void iwl_pcie_rx_mq_hw_init(struc
 	for (i = 0; i < trans->num_rx_queues; i++) {
 		/* Tell device where to find RBD free table in DRAM */
 		iwl_pcie_write_prph_64(trans, RFH_Q_FRBDCB_BA_LSB(i),
-				       (u64)(rxq->bd_dma));
+				       (u64)(trans_pcie->rxq[i].bd_dma));
 		/* Tell device where to find RBD used table in DRAM */
 		iwl_pcie_write_prph_64(trans, RFH_Q_URBDCB_BA_LSB(i),
-				       (u64)(rxq->used_bd_dma));
+				       (u64)(trans_pcie->rxq[i].used_bd_dma));
 		/* Tell device where in DRAM to update its Rx status */
 		iwl_pcie_write_prph_64(trans, RFH_Q_URBD_STTS_WPTR_LSB(i),
-				       rxq->rb_stts_dma);
+				       trans_pcie->rxq[i].rb_stts_dma);
 		/* Reset device indice tables */
 		iwl_write_prph(trans, RFH_Q_FRBDCB_WIDX(i), 0);
 		iwl_write_prph(trans, RFH_Q_FRBDCB_RIDX(i), 0);
@@ -808,6 +809,12 @@ static void iwl_pcie_rx_init_rxb_lists(s
 	rxq->used_count = 0;
 }
 
+static int iwl_pcie_dummy_napi_poll(struct napi_struct *napi, int budget)
+{
+	WARN_ON(1);
+	return 0;
+}
+
 int iwl_pcie_rx_init(struct iwl_trans *trans)
 {
 	struct iwl_trans_pcie *trans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);
@@ -857,6 +864,10 @@ int iwl_pcie_rx_init(struct iwl_trans *t
 
 		iwl_pcie_rx_init_rxb_lists(rxq);
 
+		if (!rxq->napi.poll)
+			netif_napi_add(&trans_pcie->napi_dev, &rxq->napi,
+				       iwl_pcie_dummy_napi_poll, 64);
+
 		spin_unlock(&rxq->lock);
 	}
 
@@ -878,7 +889,7 @@ int iwl_pcie_rx_init(struct iwl_trans *t
 
 	iwl_pcie_rxq_alloc_rbs(trans, GFP_KERNEL, def_rxq);
 	if (trans->cfg->mq_rx_supported) {
-		iwl_pcie_rx_mq_hw_init(trans, def_rxq);
+		iwl_pcie_rx_mq_hw_init(trans);
 	} else {
 		iwl_pcie_rxq_restock(trans, def_rxq);
 		iwl_pcie_rx_hw_init(trans, def_rxq);
@@ -940,6 +951,9 @@ void iwl_pcie_rx_free(struct iwl_trans *
 					  rxq->used_bd, rxq->used_bd_dma);
 		rxq->used_bd_dma = 0;
 		rxq->used_bd = NULL;
+
+		if (rxq->napi.poll)
+			netif_napi_del(&rxq->napi);
 	}
 	kfree(trans_pcie->rxq);
 }
@@ -1055,7 +1069,12 @@ static void iwl_pcie_rx_handle_rb(struct
 		index = SEQ_TO_INDEX(sequence);
 		cmd_index = get_cmd_index(&txq->q, index);
 
-		iwl_op_mode_rx(trans->op_mode, &trans_pcie->napi, &rxcb);
+		if (rxq->id == 0)
+			iwl_op_mode_rx(trans->op_mode, &rxq->napi,
+				       &rxcb);
+		else
+			iwl_op_mode_rx_rss(trans->op_mode, &rxq->napi,
+					   &rxcb, rxq->id);
 
 		if (reclaim) {
 			kzfree(txq->entries[cmd_index].free_buf);
@@ -1236,8 +1255,8 @@ restart:
 	if (unlikely(emergency && count))
 		iwl_pcie_rxq_alloc_rbs(trans, GFP_ATOMIC, rxq);
 
-	if (trans_pcie->napi.poll)
-		napi_gro_flush(&trans_pcie->napi, false);
+	if (rxq->napi.poll)
+		napi_gro_flush(&rxq->napi, false);
 }
 
 /*
--- a/drivers/net/wireless/iwlwifi/pcie/trans.c
+++ b/drivers/net/wireless/iwlwifi/pcie/trans.c
@@ -1428,12 +1428,6 @@ static void iwl_trans_pcie_write_prph(st
 	iwl_trans_pcie_write32(trans, HBUS_TARG_PRPH_WDAT, val);
 }
 
-static int iwl_pcie_dummy_napi_poll(struct napi_struct *napi, int budget)
-{
-	WARN_ON(1);
-	return 0;
-}
-
 static void iwl_trans_pcie_configure(struct iwl_trans *trans,
 				     const struct iwl_trans_config *trans_cfg)
 {
@@ -1470,11 +1464,8 @@ static void iwl_trans_pcie_configure(str
 	 * As this function may be called again in some corner cases don't
 	 * do anything if NAPI was already initialized.
 	 */
-	if (!trans_pcie->napi.poll) {
+	if (trans_pcie->napi_dev.reg_state != NETREG_DUMMY)
 		init_dummy_netdev(&trans_pcie->napi_dev);
-		netif_napi_add(&trans_pcie->napi_dev, &trans_pcie->napi,
-			       iwl_pcie_dummy_napi_poll, 64);
-	}
 }
 
 void iwl_trans_pcie_free(struct iwl_trans *trans)
@@ -1498,9 +1489,6 @@ void iwl_trans_pcie_free(struct iwl_tran
 	pci_release_regions(trans_pcie->pci_dev);
 	pci_disable_device(trans_pcie->pci_dev);
 
-	if (trans_pcie->napi.poll)
-		netif_napi_del(&trans_pcie->napi);
-
 	iwl_pcie_free_fw_monitor(trans);
 
 	for_each_possible_cpu(i) {
